{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 페이지의 이미지 데이터를 수집하기\n",
    "키워드로 검색후, 검색결과를 순차적으로 조회해서 상세페이지의 이미지 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import urllib\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"예제: 대한민국 구석구석 사이트의 여행지 정보 수집하기\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "query_txt = input(\"크롤링할 키워드는 입력:\")\n",
    "cnt = int(input(\"크롤링할 건색 건수:\"))\n",
    "item_per_page=10\n",
    "page_cnt = math.ceil(cnt/item_per_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dir = input(\"결과 폴더들을 저장할 디렉토리 입력 (C:\\\\Study\\\\Python\\\\notebook\\\\data\\\\):\")\n",
    "n = time.localtime()\n",
    "s = '{}-{}-{}-{}-{}'.format(n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min)\n",
    "dir_name=f_dir+s+'-'+query_txt\n",
    "os.makedirs(dir_name)\n",
    "\n",
    "dir_name +='\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver 생성 및 웹사이트 소환\n",
    "s_time = time.time()\n",
    "\n",
    "path=\"C:\\\\Study\\\\Python\\\\datadown\\\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(\"https://korean.visitkorea.or.kr/\")\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_xpath('//*[@id=\"chkForm01\"]').click()\n",
    "except:\n",
    "    print('코로나 창이 없습니다.')\n",
    "\n",
    "#검색실행\n",
    "element = driver.find_element_by_id(\"inp_search\")\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print('크롤링할 키워드:',query_txt)\n",
    "print('크롤링할 총 페이지 번호:',page_cnt)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no =1 #검색건수 카운터 (1~cnt)\n",
    "catalog = {} #상세페이지 title별 이미지리스트 dictionary: key:title, value:img_src2리스트\n",
    "\n",
    "for x in range(1,page_cnt+1):\n",
    "    print('{}페이지의 데이터를 가져옵니다.============='.format(x))\n",
    "    \n",
    "    for y in range(1,item_per_page+1):\n",
    "        #요청한 검색건수에 도달하면 for loop나오기\n",
    "        if no > cnt:\n",
    "            break\n",
    "            \n",
    "        #검색결과들의 상세페이지로 이동    \n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"listBody\"]/ul/li[{}]/div[2]/div[1]/a'.format(y)).click()\n",
    "        except:\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #상세페이지 소스코드 받아서 soup객체 생성 \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        img_src1=[] # 이미지url 리스트\n",
    "        \n",
    "        #상세페이지 유형별로 이미지 가져오기\n",
    "        try:\n",
    "            try:\n",
    "                #상세페이지 제목받아오기 (폴더이름으로 사용예정)\n",
    "                title = soup.find('div', id='contents').find('h2').get_text()\n",
    "\n",
    "                #페이지에서 tab별 이미지url 받아오기\n",
    "                num_thumbs=4\n",
    "                for z in range(1,num_thumbs+1):\n",
    "                    driver.find_element_by_xpath('//*[@id=\"contents\"]/div[2]/div[6]/div[1]/div[1]/div/ul/li[%s]/a'%z).click()\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    html = driver.page_source\n",
    "                    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "                    tab = soup.find('div',\"cos_cont active\")\n",
    "                    tab2 = tab.find('div','info_area pc').find_all('a')\n",
    "\n",
    "                    for i in tab2:\n",
    "                        img_src = i['style'].split(\"(\")[1].split(\")\")[0]\n",
    "                        img_src1.append(img_src) #리스트에 저장\n",
    "\n",
    "                catalog[title]=img_src1  \n",
    "                print(no,') 유형1:',title)\n",
    "            except:\n",
    "                try:\n",
    "                    #상세페이지 제목받아오기 (폴더이름으로 사용예정)\n",
    "                    title = soup.find('div','tit_cont titleType1').find('h2', id='topTitle').get_text()\n",
    "\n",
    "                    #상세페이지 이미지 받아오기\n",
    "                    img_src = soup.find('div','box_txtPhoto').find_all('img')\n",
    "                    for i in img_src:\n",
    "                        img_src=i['src']\n",
    "                        img_src1.append(img_src)\n",
    "\n",
    "                    catalog[title]=img_src1\n",
    "                    print(no,') 유형2:',title)\n",
    "                except:\n",
    "                    try:\n",
    "                        #상세페이지 제목받아오기 (폴더이름으로 사용예정)\n",
    "                        #title = soup.find('div','titTypeWrap').find('h3').get_text()\n",
    "                        #유형3에서 title이 div titTypeWrap이 아닌경우가 있음.\n",
    "                        title = soup.find('div','titleType1').find('h2',id='topTitle').get_text()\n",
    "\n",
    "                        #상세페이지에서 이미지 리스트받아오기\n",
    "                        img_group = soup.find('div','swiper-wrapper').find_all(['div','style']) #pImgList를 담은 div태그\n",
    "\n",
    "                        for k in img_group:\n",
    "                            img_src = (str(k).split('(\"')[1].split('\")')[0])\n",
    "                            #url 보정 ('amp'빼야함)\n",
    "                            img_src = img_src.replace('amp;','')\n",
    "                            img_src1.append(img_src)\n",
    "\n",
    "                        catalog[title]= img_src1\n",
    "                        print(no,') 유형3:',title)\n",
    "                    except:\n",
    "                        print(no,') 유형unkown: 이미지를 가져올 수 없습니다.')\n",
    "        except:\n",
    "            print('no',no)\n",
    "            no +=1\n",
    "            driver.back()\n",
    "            continue\n",
    "            \n",
    "        print('no',no)\n",
    "        no +=1\n",
    "        driver.back()\n",
    "        time.sleep(2)\n",
    "        #여기까지 item별 loop\n",
    "\n",
    "\n",
    "    x += 1\n",
    "    print('x',x)             \n",
    "    if(x % 5 == 1):\n",
    "        driver.find_element_by_link_text(\"다음\").click()\n",
    "    else:\n",
    "        driver.find_element_by_link_text(\"{}\".format(x)).click()\n",
    "        \n",
    "    time.sleep(2)  \n",
    "    #여기까지 page별 loop                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dir_list=[] #폴더 리스트\n",
    "title_list = list(catalog.keys())\n",
    "img_list = list(catalog.values())\n",
    "\n",
    "print(title_list)\n",
    "print(img_list)\n",
    "\n",
    "#title별 폴더만들기\n",
    "for t in title_list:           \n",
    "    now = time.localtime()\n",
    "    s = '{}-{}-{}-{}-{}' .format(now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min)\n",
    "    f_dir_name = dir_name+s+'-'+t\n",
    "    os.makedirs(f_dir_name)\n",
    "    #폴더 리스트에 추가\n",
    "    f_dir_list.append(f_dir_name)\n",
    " \n",
    "#폴더별로 이미지 저장  \n",
    "for i in range(0,len(img_list)):\n",
    "    file_no=0 #이미지 순번   \n",
    "    \n",
    "    #이미지를 저장하려는 위치로 디렉토리를 변경\n",
    "    os.chdir(f_dir_list[i])\n",
    "    print(\"폴더: \"+f_dir_list[i]+\"에 저장 시작:\")    \n",
    "    for j in range(0,len(img_list[i])):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(img_list[i][j],str(file_no)+'.jpg')\n",
    "        except:\n",
    "            continue\n",
    "        file_no+=1\n",
    "        time.sleep(0.5)\n",
    "        print(\"%s번째 이미지 저장중입니다.\"%file_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_time = time.time()\n",
    "d_time = e_time - s_time\n",
    "\n",
    "print(\"=\" *80)\n",
    "print(\"총 소요시간은 %s 초 입니다 \" %round(d_time,1))\n",
    "total=0\n",
    "for i in img_list:\n",
    "    total += len(i)\n",
    "print(\"총 저장 건수는 %s 건 입니다 \" %(total))\n",
    "print(\"파일이 저장된 폴더들의 경로는 입니다\")\n",
    "for x in f_dir_list:\n",
    "    print(x)\n",
    "print(\"=\" *80)\n",
    " \n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "#유형 3 연습\n",
    "\n",
    "no =1 #검색건수 카운터 (1~cnt)\n",
    "catalog = {} #상세페이지 title별 이미지리스트 dictionary: key:title, value:img_src2리스트\n",
    "\n",
    "#상세페이지 소스코드 받아서 soup객체 생성 \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "img_src1=[] # 이미지url 리스트\n",
    "\n",
    "try:\n",
    "    #상세페이지 제목받아오기 (폴더이름으로 사용예정)\n",
    "    #title = soup.find('div','titTypeWrap').find('h3').get_text()\n",
    "    \n",
    "    title = soup.find('div','titleType1').find('h2',id='topTitle').get_text()\n",
    "    print(title)\n",
    "    \n",
    "    #상세페이지에서 이미지 리스트받아오기\n",
    "    img_group = soup.find('div','swiper-wrapper').find_all(['div','style']) #pImgList를 담은 div태그\n",
    "    \n",
    "    for k in img_group:\n",
    "        img_src = (str(k).split('(\"')[1].split('\")')[0])\n",
    "        img_src1.append(img_src)\n",
    "    \n",
    "    for x in img_src1:\n",
    "        x=x.replace('amp;','')\n",
    "        print(x)\n",
    "   \n",
    "    catalog[title]= img_src1\n",
    "    print(no,') 유형3:',title)\n",
    "\n",
    "except:\n",
    "    print(no,') 유형unkown: 이미지를 가져올 수 없습니다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata",
   "language": "python",
   "name": "pydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
