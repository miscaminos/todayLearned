{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup는 웹크롤러에서 가장 중요한 요소 중에 하나이다.\n",
    "# Beautiful Soup를 이용하여 HTML 코드 전체를 대상으로 우리가 원하는\n",
    "# 태그를 찾을때 단 한줄로 이작업을 할 수 있다. \n",
    "# 웹 관련 작업을 하기 위해서 꼭 알아야 할 라이브러리 이다.\n",
    "# 웹 크롤러를 만들려면 파이썬의 기초 문법, HTML 언어의 내용까지 알고 있어야 한다.\n",
    "\n",
    "# Beautiful Soup를 사용하기 위해서는 먼저 설치를 해야 한다.\n",
    "# jupyter notebook 에서 bs4 파일을 생성한다.\n",
    "# anaconda prompt 또는 jupyter notebook에서 명령을 실행하여 Beautiful Soup 4 설치를 한다.\n",
    "\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- -------------------\n",
      "alabaster                     0.7.12\n",
      "appdirs                       1.4.4\n",
      "argh                          0.26.2\n",
      "astroid                       2.5\n",
      "async-generator               1.10\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         20.3.0\n",
      "autopep8                      1.5.6\n",
      "Babel                         2.9.0\n",
      "backcall                      0.2.0\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.9.3\n",
      "black                         19.10b0\n",
      "bleach                        3.3.0\n",
      "brotlipy                      0.7.0\n",
      "bs4                           0.0.1\n",
      "certifi                       2020.12.5\n",
      "cffi                          1.14.5\n",
      "chardet                       4.0.0\n",
      "click                         7.1.2\n",
      "cloudpickle                   1.6.0\n",
      "colorama                      0.4.4\n",
      "cryptography                  3.4.7\n",
      "cx-Oracle                     8.1.0\n",
      "cycler                        0.10.0\n",
      "decorator                     5.0.3\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "docutils                      0.16\n",
      "entrypoints                   0.3\n",
      "et-xmlfile                    1.0.1\n",
      "flake8                        3.9.0\n",
      "future                        0.18.2\n",
      "greenlet                      1.0.0\n",
      "idna                          2.10\n",
      "imagesize                     1.2.0\n",
      "importlib-metadata            3.7.3\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     5.3.4\n",
      "ipython                       7.22.0\n",
      "ipython-genutils              0.2.0\n",
      "isort                         5.8.0\n",
      "jedi                          0.17.2\n",
      "Jinja2                        2.11.3\n",
      "jsonschema                    3.2.0\n",
      "jupyter-client                6.1.12\n",
      "jupyter-core                  4.7.1\n",
      "jupyterlab-pygments           0.1.2\n",
      "keyring                       22.3.0\n",
      "kiwisolver                    1.3.1\n",
      "lazy-object-proxy             1.6.0\n",
      "MarkupSafe                    1.1.1\n",
      "matplotlib                    3.3.4\n",
      "mccabe                        0.6.1\n",
      "mistune                       0.8.4\n",
      "mkl-fft                       1.3.0\n",
      "mkl-random                    1.1.1\n",
      "mkl-service                   2.3.0\n",
      "mypy-extensions               0.4.3\n",
      "nbclient                      0.5.3\n",
      "nbconvert                     6.0.7\n",
      "nbformat                      5.1.3\n",
      "nest-asyncio                  1.5.1\n",
      "numpy                         1.19.2\n",
      "numpydoc                      1.1.0\n",
      "olefile                       0.46\n",
      "openpyxl                      3.0.7\n",
      "packaging                     20.9\n",
      "pandas                        1.2.3\n",
      "pandocfilters                 1.4.3\n",
      "paramiko                      2.7.2\n",
      "parso                         0.7.0\n",
      "pathspec                      0.7.0\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        8.2.0\n",
      "pip                           21.0.1\n",
      "pluggy                        0.13.1\n",
      "prompt-toolkit                3.0.17\n",
      "psutil                        5.8.0\n",
      "ptyprocess                    0.7.0\n",
      "pycodestyle                   2.6.0\n",
      "pycparser                     2.20\n",
      "pydocstyle                    6.0.0\n",
      "pyflakes                      2.2.0\n",
      "Pygments                      2.8.1\n",
      "pylint                        2.7.4\n",
      "pyls-black                    0.4.6\n",
      "pyls-spyder                   0.3.2\n",
      "PyNaCl                        1.4.0\n",
      "pyOpenSSL                     20.0.1\n",
      "pyparsing                     2.4.7\n",
      "pyrsistent                    0.17.3\n",
      "PySocks                       1.7.1\n",
      "python-dateutil               2.8.1\n",
      "python-jsonrpc-server         0.4.0\n",
      "python-language-server        0.36.2\n",
      "pytz                          2021.1\n",
      "pywin32                       227\n",
      "pywin32-ctypes                0.2.0\n",
      "PyYAML                        5.4.1\n",
      "pyzmq                         20.0.0\n",
      "QDarkStyle                    2.8.1\n",
      "QtAwesome                     1.0.2\n",
      "qtconsole                     5.0.3\n",
      "QtPy                          1.9.0\n",
      "regex                         2021.3.17\n",
      "requests                      2.25.1\n",
      "rope                          0.18.0\n",
      "Rtree                         0.9.4\n",
      "scipy                         1.6.2\n",
      "seaborn                       0.11.1\n",
      "selenium                      3.141.0\n",
      "setuptools                    52.0.0.post20210125\n",
      "six                           1.15.0\n",
      "snowballstemmer               2.1.0\n",
      "sortedcontainers              2.3.0\n",
      "soupsieve                     2.2.1\n",
      "Sphinx                        3.5.3\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        1.0.3\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.4\n",
      "spyder                        4.2.5\n",
      "spyder-kernels                1.10.2\n",
      "SQLAlchemy                    1.4.7\n",
      "testpath                      0.4.4\n",
      "textdistance                  4.2.1\n",
      "three-merge                   0.1.1\n",
      "toml                          0.10.2\n",
      "tornado                       6.1\n",
      "traitlets                     5.0.5\n",
      "typed-ast                     1.4.2\n",
      "typing-extensions             3.7.4.3\n",
      "ujson                         4.0.2\n",
      "urllib3                       1.26.4\n",
      "watchdog                      1.0.2\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "wheel                         0.36.2\n",
      "win-inet-pton                 1.1.0\n",
      "wincertstore                  0.2\n",
      "wrapt                         1.12.1\n",
      "xlrd                          2.0.1\n",
      "xlwt                          1.3.0\n",
      "yapf                          0.31.0\n",
      "zipp                          3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup로 웹의 데이터를 가져온다는 것은 \n",
    "## 웹의 태그를 가져온다는 의미다.\n",
    "\n",
    "태그를 가져오는 방법은 find(), find_all(), select()함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) find(): 조건을 만족하는 태그 하나만 가져온다.\n",
    "\n",
    "# - Beautiful Soup 객체에는 find()가 있다.\n",
    "# - HTML 코드 안에서 원하는 태그를 가져올 수 있다.\n",
    "# - 찾고 싶은 태그가 없다면 아무 내용이 나오지 않는다.\n",
    "# - 동일한 태그가 여러 개 있을 경우 첫 번째 태그 1개만 가져온다.\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1='''\n",
    "<html>\n",
    "    <head>\n",
    "        <title> HTML연습 </title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p align=\"center\"> text1 </p>\n",
    "        <img src = \"C:\\\\LSJ\\\\figures\\\\running.jpg\">\n",
    "    </body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title> HTML연습 </title>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(ex1, 'html.parser')\n",
    "soup.find('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<p align=\"center\"> text1 </p>\n",
       "<img src=\"C:\\LSJ\\figures\\running.jpg\"/>\n",
       "</body>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"center\"> text1 </p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 속성값을 이용하여 원하는 태그를 추출할 수도 있다.\n",
    "ex1 = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title> HTML 연습 </title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p align=\"center\"> text 1 </p>\n",
    "        <p align=\"right\"> text 2 </p>\n",
    "        <p align=\"left\"> text 3 </p>\n",
    "        <img src = \"C:\\\\LSJ\\\\figures\\\\running.jpg\">\n",
    "    </body>\n",
    "</html> '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"center\"> text 1 </p>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(ex1, 'html.parser')\n",
    "soup.find('p', align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"right\"> text 2 </p>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p', align='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\"> text 3 </p>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p', align='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) find_all(): 해당 태그가 여러개 있을경우, 한꺼번에 모두 가져온다.\n",
    "# 웹 페이지는 동일한 태그가 아주 많이 있기 때문에 find_all() 함수를 사용한다.\n",
    "# 결과는 리스트 객체에 담아온다.\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1='''\n",
    "<html>\n",
    "    <head>\n",
    "        <title> HTML 연습 </title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p align=\"center\"> text 1 </p>\n",
    "        <p align=\"center\"> text 2 </p>\n",
    "        <p align=\"center\"> text 3 </p>\n",
    "        <img src = \"C:\\\\LSJ\\\\figures\\\\running.jpg\">\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(ex1 , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"center\"> text 1 </p>,\n",
       " <p align=\"center\"> text 2 </p>,\n",
       " <p align=\"center\"> text 3 </p>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=soup.find_all('p')\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p align=\"center\"> ', ' 1 </p>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(k[0]).split('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"center\"> text 1 </p>,\n",
       " <p align=\"center\"> text 2 </p>,\n",
       " <p align=\"center\"> text 3 </p>,\n",
       " <img src=\"C:\\LSJ\\figures\\running.jpg\"/>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all( ['p','img']) #찾은 여러 태그를 리스트에 넣어 찾아온다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"center\"> text 1 </p>,\n",
       " <p align=\"center\"> text 2 </p>,\n",
       " <p align=\"center\"> text 3 </p>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(align='center')#속성으로 여러 태그를 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' text 1 '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) 문장 가져오기 (.string 또는 .get_text() 사용)\n",
    "# 화면에 보여지는 내용(문장이나 이미지등)을 가져올 수 있다.\n",
    "# 아래 소스는 find()로 첫번째 p태그를 가져와서 p태그가 감싸고 있는 내용을 가져온다.\n",
    "\n",
    "txt = soup.find('p') #첫번째 p태그 가져오기\n",
    "txt.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p align=\"center\"> text 1 </p>, <p align=\"center\"> text 2 </p>, <p align=\"center\"> text 3 </p>]\n",
      "<p align=\"center\"> text 1 </p>\n",
      "<p align=\"center\"> text 2 </p>\n",
      "<p align=\"center\"> text 3 </p>\n",
      " text 1 \n",
      " text 2 \n",
      " text 3 \n"
     ]
    }
   ],
   "source": [
    "txt2 = soup.find_all('p')\n",
    "#찾은 p 태그들을 txt2 리스트에 넣어 찾아온다 \n",
    "print(txt2)\n",
    "\n",
    "for i in txt2:\n",
    "    print(i)\n",
    "    \n",
    "#리스트를 traverse하면서 i.string으로 각 태그의 문장만 가져온다\n",
    "for i in txt2:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " text 1 \n",
      " text 2 \n",
      " text 3 \n"
     ]
    }
   ],
   "source": [
    "txt3 = soup.find_all('p')\n",
    "\n",
    "#리스트를 traverse하면서 i.get_text()로 각 태그의 문장만 가져온다\n",
    "for i in txt3:\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) select() 함수를 사용하여 원하는 데이터 추출하기\n",
    "# css_selector를 이용하여 원하는 태그를 찾는 방법이 있다.\n",
    "\n",
    "# 잠깐 review: \n",
    "#css(Cascading Style Sheet)는 HTML 등의 마크업 언어로 작성된 문서가\n",
    "# 실제로 웹사이트에 표현되는 방법을 정해주는 언어이다.\n",
    "# css selector는 HTML 등의 마크업 언어로 작성된 문서에서 특정 요소(태그)를 찾을 수 있으며, \n",
    "# 세가지 방법이 있다:\n",
    "\n",
    "# 1. 태그이름으로 찾는 selector : p 태그 찾아서 내용 설정한다.\n",
    "#        p {\n",
    "#           text-align: center;\n",
    "#           color: red;\n",
    "#        }\n",
    "    \n",
    "# 2. 아이디로 찾는 selector : 속성 id='para1'인 태그를 찾아 내용 설정한다.\n",
    "#         #para1 {\n",
    "#               text-align: center;\n",
    "#               color: red;\n",
    "#         }\n",
    "# 3. 클래스로 찾는 selector : 속성 class= 'center'인 태그를 찾아 내용 설정한다.\n",
    "#       .center {\n",
    "#             text-align: center;\n",
    "#             color: red;\n",
    "#        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = ''' \n",
    "<html> \n",
    "    <head> \n",
    "        <title> 사야할 과일 </title> \n",
    "    </head> \n",
    "    <body> \n",
    "        <h1> 시장가서 사야할 과일 목록 </h1>\n",
    "            <div>\n",
    "                 <p id='fruits1' class='name1' title='바나나'> 바나나 \n",
    "                   <span class = 'price'> 3000원 </span> \n",
    "                   <span class = 'count'> 10개 </span> \n",
    "                   <span class = 'store'> 바나나가게 </span> \n",
    "                   <a href = 'https://www.fruit1.com'> banana</a> \n",
    "                  </p>\n",
    "            </div> \n",
    "            <div>\n",
    "                 <p id='fruits2' class='name2' title='체리'> 체리 \n",
    "                  <span class = 'price'> 100원 </span> \n",
    "                  <span class = 'count'> 50개 </span> \n",
    "                  <span class = 'store'> 체리가게</span> \n",
    "                  <a href = 'https://www.fruit2.com'> cherry </a>\n",
    "                </p> \n",
    "            </div> \n",
    "            <div>\n",
    "                <p id='fruits3' class='name3' title='오렌지'> 오렌지\n",
    "                  <span class = 'price'> 500원 </span> \n",
    "                  <span class = 'count'> 20개 </span> \n",
    "                  <span class = 'store'> 오렌지가게</span> \n",
    "                  <a href = 'https://www.fruit3.com'> orange </a>\n",
    "                </p> \n",
    "            </div> \n",
    "    </body> \n",
    "</html> ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(ex2, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"name1\" id=\"fruits1\" title=\"바나나\"> 바나나 \n",
       "                    <span class=\"price\"> 3000원 </span>\n",
       " <span class=\"count\"> 10개 </span>\n",
       " <span class=\"store\"> 바나나가게 </span>\n",
       " <a href=\"https://www.fruit1.com\"> banana</a>\n",
       " </p>,\n",
       " <p class=\"name2\" id=\"fruits2\" title=\"체리\"> 체리 \n",
       "                   <span class=\"price\"> 100원 </span>\n",
       " <span class=\"count\"> 50개 </span>\n",
       " <span class=\"store\"> 체리가게</span>\n",
       " <a href=\"https://www.fruit2.com\"> cherry </a>\n",
       " </p>,\n",
       " <p class=\"name3\" id=\"fruits3\" title=\"오렌지\"> 오렌지\n",
       "                   <span class=\"price\"> 500원 </span>\n",
       " <span class=\"count\"> 20개 </span>\n",
       " <span class=\"store\"> 오렌지가게</span>\n",
       " <a href=\"https://www.fruit3.com\"> orange </a>\n",
       " </p>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('p') #p태그들을 다 검색한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"name1\" id=\"fruits1\" title=\"바나나\"> 바나나 \n",
       "                    <span class=\"price\"> 3000원 </span>\n",
       " <span class=\"count\"> 10개 </span>\n",
       " <span class=\"store\"> 바나나가게 </span>\n",
       " <a href=\"https://www.fruit1.com\"> banana</a>\n",
       " </p>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select('.클래스명'): class 속성의 값으로 추출\n",
    "soup2.select('.name1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"name1\" id=\"fruits1\" title=\"바나나\"> 바나나 \n",
       "                    <span class=\"price\"> 3000원 </span>\n",
       " <span class=\"count\"> 10개 </span>\n",
       " <span class=\"store\"> 바나나가게 </span>\n",
       " <a href=\"https://www.fruit1.com\"> banana</a>\n",
       " </p>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select('#아이디명') : id 속성의 값으로 추출\n",
    "soup2.select('#fruits1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"price\"> 3000원 </span>,\n",
       " <span class=\"count\"> 10개 </span>,\n",
       " <span class=\"store\"> 바나나가게 </span>,\n",
       " <span class=\"price\"> 100원 </span>,\n",
       " <span class=\"count\"> 50개 </span>,\n",
       " <span class=\"store\"> 체리가게</span>,\n",
       " <span class=\"price\"> 500원 </span>,\n",
       " <span class=\"count\"> 20개 </span>,\n",
       " <span class=\"store\"> 오렌지가게</span>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select('상위태그 > 하위태그 > 하위태그') :  '>'로 단계적으로 태그를 찾는다.\n",
    "#  '>' 태그 사이에는 공백이 반드시 들어가야 한다.\n",
    "soup2.select('div > p > span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"price\"> 3000원 </span>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('div > p > span')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup2.select('div > p > span'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"store\"> 바나나가게 </span>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select('상위태그.클래스이름' > '하위태그.클래스이름')\n",
    "soup2.select('p.name1 > span.store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"store\"> 바나나가게 </span>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select('#아이디명 > 태그명.클래스명')\n",
    "soup2.select('#fruits1 > span.store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.fruit1.com\"> banana</a>,\n",
       " <a href=\"https://www.fruit2.com\"> cherry </a>,\n",
       " <a href=\"https://www.fruit3.com\"> orange </a>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select('태그명[속성1=값'])\n",
    "soup2.select('a[href]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"name1\" id=\"fruits1\" title=\"바나나\"> 바나나 \n",
       "                    <span class=\"price\"> 3000원 </span>\n",
       " <span class=\"count\"> 10개 </span>\n",
       " <span class=\"store\"> 바나나가게 </span>\n",
       " <a href=\"https://www.fruit1.com\"> banana</a>\n",
       " </p>,\n",
       " <p class=\"name2\" id=\"fruits2\" title=\"체리\"> 체리 \n",
       "                   <span class=\"price\"> 100원 </span>\n",
       " <span class=\"count\"> 50개 </span>\n",
       " <span class=\"store\"> 체리가게</span>\n",
       " <a href=\"https://www.fruit2.com\"> cherry </a>\n",
       " </p>,\n",
       " <p class=\"name3\" id=\"fruits3\" title=\"오렌지\"> 오렌지\n",
       "                   <span class=\"price\"> 500원 </span>\n",
       " <span class=\"count\"> 20개 </span>\n",
       " <span class=\"store\"> 오렌지가게</span>\n",
       " <a href=\"https://www.fruit3.com\"> orange </a>\n",
       " </p>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('p[title]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata",
   "language": "python",
   "name": "pydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
